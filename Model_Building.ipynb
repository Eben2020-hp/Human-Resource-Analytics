{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>  HR ANALYTICS CHALLENGE </h1>\r\n",
    "<h3 align='center'> <b>Predict Whether a Potential Promotee Will be Promoted or Not</b> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Challenge**\r\n",
    "\r\n",
    "HR analytics is revolutionising the way human resources departments operate, leading to higher efficiency and better results overall. Human resources has been using analytics for years. However, the collection, processing and analysis of data has been largely manual, and given the nature of human resources dynamics and HR KPIs, the approach has been constraining HR. Therefore, it is surprising that HR departments woke up to the utility of machine learning so late in the game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import relevant Dependencies\r\n",
    "\r\n",
    "Incase you are getting any error saying the package is not installed while running the below cell, then you can use two methods:\r\n",
    "- pip install ________.\r\n",
    "- google 'How to install ________'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies -To see the graphs in the notebook.\r\n",
    "%matplotlib inline   \r\n",
    "\r\n",
    "# Python Imports\r\n",
    "import math,time,random,datetime\r\n",
    "\r\n",
    "# Data Manipulation\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Visualization -This is where the graphs come in.\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import missingno\r\n",
    "plt.style.use('fivethirtyeight')\r\n",
    "\r\n",
    "# Preprocessing\r\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\r\n",
    "\r\n",
    "# Machine Learning\r\n",
    "import catboost\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from catboost import CatBoostClassifier, Pool, cv\r\n",
    "\r\n",
    "# Performance Metrics\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "# Ignore Warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# Display all the columns/rows of the DataFrame.\r\n",
    "pd.set_option('display.max_columns', None)\r\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train data.\r\n",
    "train = pd.read_csv('Final_train.csv')\r\n",
    "test = pd.read_csv('Final_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Building\r\n",
    "\r\n",
    "### Algorithms\r\n",
    "From here, we will be running the following algorithms.\r\n",
    "\r\n",
    "- Logistic Regression\r\n",
    "- KNN\r\n",
    "- Naive Bayes\r\n",
    "- Stochastic Gradient Decent\r\n",
    "- Linear SVC\r\n",
    "- Decision Tree\r\n",
    "- Gradient Boosted Trees\r\n",
    "- Random Forest\r\n",
    "- CatBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808933</td>\n",
       "      <td>-1.536223</td>\n",
       "      <td>1.154111</td>\n",
       "      <td>-0.415276</td>\n",
       "      <td>-0.284763</td>\n",
       "      <td>1.385021</td>\n",
       "      <td>0.500460</td>\n",
       "      <td>1.356878</td>\n",
       "      <td>-0.154018</td>\n",
       "      <td>-1.075931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.388183</td>\n",
       "      <td>0.650947</td>\n",
       "      <td>-0.885239</td>\n",
       "      <td>-0.415276</td>\n",
       "      <td>-0.284763</td>\n",
       "      <td>1.385021</td>\n",
       "      <td>-0.437395</td>\n",
       "      <td>-0.736986</td>\n",
       "      <td>-0.154018</td>\n",
       "      <td>-0.253282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808933</td>\n",
       "      <td>0.650947</td>\n",
       "      <td>1.154111</td>\n",
       "      <td>-0.415276</td>\n",
       "      <td>-0.284763</td>\n",
       "      <td>-0.259125</td>\n",
       "      <td>0.265996</td>\n",
       "      <td>-0.736986</td>\n",
       "      <td>-0.154018</td>\n",
       "      <td>-1.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808933</td>\n",
       "      <td>0.650947</td>\n",
       "      <td>-0.885239</td>\n",
       "      <td>1.226063</td>\n",
       "      <td>0.718471</td>\n",
       "      <td>-1.903271</td>\n",
       "      <td>0.969387</td>\n",
       "      <td>-0.736986</td>\n",
       "      <td>-0.154018</td>\n",
       "      <td>-1.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.207972</td>\n",
       "      <td>0.650947</td>\n",
       "      <td>-0.885239</td>\n",
       "      <td>-0.415276</td>\n",
       "      <td>1.721705</td>\n",
       "      <td>-0.259125</td>\n",
       "      <td>-0.906322</td>\n",
       "      <td>-0.736986</td>\n",
       "      <td>-0.154018</td>\n",
       "      <td>0.718939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_promoted  department    gender  recruitment_channel  no_of_trainings  \\\n",
       "0            0    0.808933 -1.536223             1.154111        -0.415276   \n",
       "1            0   -0.388183  0.650947            -0.885239        -0.415276   \n",
       "2            0    0.808933  0.650947             1.154111        -0.415276   \n",
       "3            0    0.808933  0.650947            -0.885239         1.226063   \n",
       "4            0    1.207972  0.650947            -0.885239        -0.415276   \n",
       "\n",
       "        age  previous_year_rating  length_of_service  KPIs_met >80%  \\\n",
       "0 -0.284763              1.385021           0.500460       1.356878   \n",
       "1 -0.284763              1.385021          -0.437395      -0.736986   \n",
       "2 -0.284763             -0.259125           0.265996      -0.736986   \n",
       "3  0.718471             -1.903271           0.969387      -0.736986   \n",
       "4  1.721705             -0.259125          -0.906322      -0.736986   \n",
       "\n",
       "   awards_won?  avg_training_score  \n",
       "0    -0.154018           -1.075931  \n",
       "1    -0.154018           -0.253282  \n",
       "2    -0.154018           -1.001145  \n",
       "3    -0.154018           -1.001145  \n",
       "4    -0.154018            0.718939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns= 'is_promoted')\r\n",
    "y = train['is_promoted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcoming Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\r\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.4, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 30000, 1: 2884})\n",
      "The number of classes after fit Counter({0: 49560, 1: 49560})\n"
     ]
    }
   ],
   "source": [
    "os= SMOTETomek(random_state= 42)\r\n",
    "X_train_ns,y_train_ns = os.fit_resample(X,y)\r\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\r\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any model building, we mainly focus on 3 main steps:\r\n",
    "\r\n",
    "- Fitting the model and finding the accuracy (accuracy score) of the fitted model.\r\n",
    "- Perform K-Fold Cross Validation (K needs to be specified).\r\n",
    "- Find the accuracy of the Cross Validation. \r\n",
    "\r\n",
    "**We will be running a whole bunch of models to figure out which model is best suited for our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = LogisticRegression()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "log_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "log_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "log_acc_cv = round(metrics.accuracy_score(y_train_ns, log_train_pred)*100, 2)\r\n",
    "\r\n",
    "log_pre_cv = precision_score(y_train_ns, log_train_pred)\r\n",
    "log_rec_cv = recall_score(y_train_ns, log_train_pred)\r\n",
    "log_f1_cv = f1_score(y_train_ns, log_train_pred)\r\n",
    "\r\n",
    "log_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  72.07\n",
      "Accuracy of 10-Fold CV is:  72.08\n",
      "Running time is:  0:00:03.472665\n",
      "Precision:  0.7224639154299655\n",
      "Recall:  0.7170702179176756\n",
      "F1-Score:  0.7197569620253165\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\r\n",
    "print('Accuracy of the model is: ', log_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', log_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= log_time))\r\n",
    "\r\n",
    "print('Precision: ', log_pre_cv)\r\n",
    "print('Recall: ', log_rec_cv)\r\n",
    "print('F1-Score: ', log_f1_cv)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = KNeighborsClassifier()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "knn_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "knn_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "knn_acc_cv = round(metrics.accuracy_score(y_train_ns, knn_train_pred)*100, 2)\r\n",
    "\r\n",
    "knn_pre_cv = precision_score(y_train_ns, knn_train_pred)\r\n",
    "knn_rec_cv = recall_score(y_train_ns, knn_train_pred)\r\n",
    "knn_f1_cv = f1_score(y_train_ns, knn_train_pred)\r\n",
    "\r\n",
    "knn_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  93.83\n",
      "Accuracy of 10-Fold CV is:  90.36\n",
      "Running time is:  0:11:38.534342\n",
      "Precision:  0.8700921437294157\n",
      "Recall:  0.9488498789346247\n",
      "F1-Score:  0.907765959500415\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbours\r\n",
    "print('Accuracy of the model is: ', knn_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', knn_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= knn_time))\r\n",
    "\r\n",
    "print('Precision: ', knn_pre_cv)\r\n",
    "print('Recall: ', knn_rec_cv)\r\n",
    "print('F1-Score: ', knn_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = GaussianNB()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "gnb_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "gnb_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "gnb_acc_cv = round(metrics.accuracy_score(y_train_ns, gnb_train_pred)*100, 2)\r\n",
    "\r\n",
    "gnb_pre_cv = precision_score(y_train_ns, gnb_train_pred)\r\n",
    "gnb_rec_cv = recall_score(y_train_ns, gnb_train_pred)\r\n",
    "gnb_f1_cv = f1_score(y_train_ns, gnb_train_pred)\r\n",
    "\r\n",
    "gnb_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  67.72\n",
      "Accuracy of 10-Fold CV is:  67.73\n",
      "Running time is:  0:00:03.415667\n",
      "Precision:  0.7479959354183132\n",
      "Recall:  0.5347054075867635\n",
      "F1-Score:  0.623617451875559\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\r\n",
    "print('Accuracy of the model is: ', gnb_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', gnb_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= gnb_time))\r\n",
    "\r\n",
    "print('Precision: ', gnb_pre_cv)\r\n",
    "print('Recall: ', gnb_rec_cv)\r\n",
    "print('F1-Score: ', gnb_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4: Linear Support Vector Machines (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = LinearSVC()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "svc_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "svc_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "svc_acc_cv = round(metrics.accuracy_score(y_train_ns, svc_train_pred)*100, 2)\r\n",
    "\r\n",
    "svc_pre_cv = precision_score(y_train_ns, svc_train_pred)\r\n",
    "svc_rec_cv = recall_score(y_train_ns, svc_train_pred)\r\n",
    "svc_f1_cv = f1_score(y_train_ns, svc_train_pred)\r\n",
    "\r\n",
    "svc_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  72.47\n",
      "Accuracy of 10-Fold CV is:  72.5\n",
      "Running time is:  0:06:21.635300\n",
      "Precision:  0.7237932764676367\n",
      "Recall:  0.7276634382566586\n",
      "F1-Score:  0.7257231976656437\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machines\r\n",
    "print('Accuracy of the model is: ', svc_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', svc_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= svc_time))\r\n",
    "\r\n",
    "print('Precision: ', svc_pre_cv)\r\n",
    "print('Recall: ', svc_rec_cv)\r\n",
    "print('F1-Score: ', svc_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = SGDClassifier()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "SGD_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "SGD_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "SGD_acc_cv = round(metrics.accuracy_score(y_train_ns, SGD_train_pred)*100, 2)\r\n",
    "\r\n",
    "SGD_pre_cv = precision_score(y_train_ns, SGD_train_pred)\r\n",
    "SGD_rec_cv = recall_score(y_train_ns, SGD_train_pred)\r\n",
    "SGD_f1_cv = f1_score(y_train_ns, SGD_train_pred)\r\n",
    "\r\n",
    "SGD_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  71.47\n",
      "Accuracy of 10-Fold CV is:  72.22\n",
      "Running time is:  0:00:07.511801\n",
      "Precision:  0.7059032517436751\n",
      "Recall:  0.7617231638418079\n",
      "F1-Score:  0.732751676549656\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\r\n",
    "print('Accuracy of the model is: ', SGD_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', SGD_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= SGD_time))\r\n",
    "\r\n",
    "print('Precision: ', SGD_pre_cv)\r\n",
    "print('Recall: ', SGD_rec_cv)\r\n",
    "print('F1-Score: ', SGD_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 6: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = DecisionTreeClassifier()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "dt_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "dt_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "dt_acc_cv = round(metrics.accuracy_score(y_train_ns, dt_train_pred)*100, 2)\r\n",
    "\r\n",
    "dt_pre_cv = precision_score(y_train_ns, dt_train_pred)\r\n",
    "dt_rec_cv = recall_score(y_train_ns, dt_train_pred)\r\n",
    "dt_f1_cv = f1_score(y_train_ns, dt_train_pred)\r\n",
    "\r\n",
    "dt_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  98.87\n",
      "Accuracy of 10-Fold CV is:  94.06\n",
      "Running time is:  0:00:07.487040\n",
      "Precision:  0.9478865440226419\n",
      "Recall:  0.9325665859564165\n",
      "F1-Score:  0.9401641595215575\n"
     ]
    }
   ],
   "source": [
    "#  Decision Tree Classifier\r\n",
    "print('Accuracy of the model is: ', dt_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', dt_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= dt_time))\r\n",
    "\r\n",
    "print('Precision: ', dt_pre_cv)\r\n",
    "print('Recall: ', dt_rec_cv)\r\n",
    "print('F1-Score: ', dt_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 7: Gradient Boost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = GradientBoostingClassifier()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "gbt_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "gbt_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "gbt_acc_cv = round(metrics.accuracy_score(y_train_ns, gbt_train_pred)*100, 2)\r\n",
    "\r\n",
    "gbt_pre_cv = precision_score(y_train_ns, gbt_train_pred)\r\n",
    "gbt_rec_cv = recall_score(y_train_ns, gbt_train_pred)\r\n",
    "gbt_f1_cv = f1_score(y_train_ns, gbt_train_pred)\r\n",
    "\r\n",
    "gbt_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  88.31\n",
      "Accuracy of 10-Fold CV is:  87.62\n",
      "Running time is:  0:02:34.256252\n",
      "Precision:  0.8428505747126437\n",
      "Recall:  0.9247376916868443\n",
      "F1-Score:  0.881897339683456\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost Trees\r\n",
    "print('Accuracy of the model is: ', gbt_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', gbt_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= gbt_time))\r\n",
    "\r\n",
    "print('Precision: ', gbt_pre_cv)\r\n",
    "print('Recall: ', gbt_rec_cv)\r\n",
    "print('F1-Score: ', gbt_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 8: Random Forest\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\r\n",
    "algorithm = RandomForestClassifier()\r\n",
    "\r\n",
    "## Step 1:\r\n",
    "model = algorithm.fit(X_train_ns,y_train_ns)      # Creating the model. We will fit the algorithm to the training data.\r\n",
    "rf_acc = round(model.score(X_train_ns,y_train_ns)*100, 2)\r\n",
    "\r\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\r\n",
    "rf_train_pred = model_selection.cross_val_predict(algorithm, X_train_ns,y_train_ns, cv= 10, n_jobs= -1)\r\n",
    "\r\n",
    "## Step 3:  --> Cross Validation accuracy metric.\r\n",
    "rf_acc_cv = round(metrics.accuracy_score(y_train_ns, rf_train_pred)*100, 2)\r\n",
    "\r\n",
    "rf_pre_cv = precision_score(y_train_ns, rf_train_pred)\r\n",
    "rf_rec_cv = recall_score(y_train_ns, rf_train_pred)\r\n",
    "rf_f1_cv = f1_score(y_train_ns, rf_train_pred)\r\n",
    "\r\n",
    "rf_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  98.87\n",
      "Accuracy of 10-Fold CV is:  95.42\n",
      "Running time is:  0:04:01.479676\n",
      "Precision:  0.9598929388689114\n",
      "Recall:  0.9479620661824052\n",
      "F1-Score:  0.9538901973523918\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is: ', rf_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', rf_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= rf_time))\r\n",
    "\r\n",
    "print('Precision: ', rf_pre_cv)\r\n",
    "print('Recall: ', rf_rec_cv)\r\n",
    "print('F1-Score: ', rf_f1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 9: CatBoost Algorithm\r\n",
    "\r\n",
    "This is by a Russian company (Yandex) who created it as an in-house algorithm but now it is open sourced.\r\n",
    "\r\n",
    "- CatBoost is a state-of-the-art open source gradient boosting on decision trees library.\r\n",
    "- It is simple and easy to use. \r\n",
    "\r\n",
    "For more details --> https://catboost.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the categorical features for CatBoost model\r\n",
    "cat_features = np.where(X_train_ns.dtypes != np.float)[0]\r\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use CatBoost Pool() function to pool together the training data and the categorical labels\r\n",
    "train_pool = Pool(X_train_ns, y_train_ns, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.5541546\ttotal: 235ms\tremaining: 23.3s\n",
      "1:\tlearn: 0.4934685\ttotal: 314ms\tremaining: 15.4s\n",
      "2:\tlearn: 0.4424429\ttotal: 366ms\tremaining: 11.8s\n",
      "3:\tlearn: 0.4113296\ttotal: 422ms\tremaining: 10.1s\n",
      "4:\tlearn: 0.3937579\ttotal: 499ms\tremaining: 9.48s\n",
      "5:\tlearn: 0.3786337\ttotal: 579ms\tremaining: 9.08s\n",
      "6:\tlearn: 0.3552970\ttotal: 627ms\tremaining: 8.33s\n",
      "7:\tlearn: 0.3465555\ttotal: 674ms\tremaining: 7.75s\n",
      "8:\tlearn: 0.3391982\ttotal: 726ms\tremaining: 7.34s\n",
      "9:\tlearn: 0.3280376\ttotal: 810ms\tremaining: 7.29s\n",
      "10:\tlearn: 0.3131784\ttotal: 860ms\tremaining: 6.96s\n",
      "11:\tlearn: 0.2994968\ttotal: 905ms\tremaining: 6.64s\n",
      "12:\tlearn: 0.2936664\ttotal: 973ms\tremaining: 6.51s\n",
      "13:\tlearn: 0.2845793\ttotal: 1.09s\tremaining: 6.7s\n",
      "14:\tlearn: 0.2786553\ttotal: 1.17s\tremaining: 6.61s\n",
      "15:\tlearn: 0.2755087\ttotal: 1.32s\tremaining: 6.93s\n",
      "16:\tlearn: 0.2678949\ttotal: 1.49s\tremaining: 7.3s\n",
      "17:\tlearn: 0.2646111\ttotal: 1.58s\tremaining: 7.21s\n",
      "18:\tlearn: 0.2605414\ttotal: 1.66s\tremaining: 7.09s\n",
      "19:\tlearn: 0.2572997\ttotal: 1.75s\tremaining: 6.98s\n",
      "20:\tlearn: 0.2516970\ttotal: 1.83s\tremaining: 6.91s\n",
      "21:\tlearn: 0.2425164\ttotal: 1.93s\tremaining: 6.86s\n",
      "22:\tlearn: 0.2376485\ttotal: 2.06s\tremaining: 6.89s\n",
      "23:\tlearn: 0.2345008\ttotal: 2.13s\tremaining: 6.75s\n",
      "24:\tlearn: 0.2309082\ttotal: 2.19s\tremaining: 6.56s\n",
      "25:\tlearn: 0.2241511\ttotal: 2.26s\tremaining: 6.43s\n",
      "26:\tlearn: 0.2205509\ttotal: 2.37s\tremaining: 6.4s\n",
      "27:\tlearn: 0.2160224\ttotal: 2.44s\tremaining: 6.27s\n",
      "28:\tlearn: 0.2119618\ttotal: 2.52s\tremaining: 6.17s\n",
      "29:\tlearn: 0.2100450\ttotal: 2.61s\tremaining: 6.1s\n",
      "30:\tlearn: 0.2064808\ttotal: 2.67s\tremaining: 5.94s\n",
      "31:\tlearn: 0.2045534\ttotal: 2.73s\tremaining: 5.79s\n",
      "32:\tlearn: 0.1999463\ttotal: 2.78s\tremaining: 5.64s\n",
      "33:\tlearn: 0.1970138\ttotal: 2.83s\tremaining: 5.49s\n",
      "34:\tlearn: 0.1949655\ttotal: 2.88s\tremaining: 5.34s\n",
      "35:\tlearn: 0.1913743\ttotal: 2.92s\tremaining: 5.2s\n",
      "36:\tlearn: 0.1886383\ttotal: 2.97s\tremaining: 5.07s\n",
      "37:\tlearn: 0.1855824\ttotal: 3.02s\tremaining: 4.93s\n",
      "38:\tlearn: 0.1829485\ttotal: 3.07s\tremaining: 4.8s\n",
      "39:\tlearn: 0.1816104\ttotal: 3.11s\tremaining: 4.66s\n",
      "40:\tlearn: 0.1785182\ttotal: 3.15s\tremaining: 4.54s\n",
      "41:\tlearn: 0.1773496\ttotal: 3.4s\tremaining: 4.69s\n",
      "42:\tlearn: 0.1747519\ttotal: 3.51s\tremaining: 4.65s\n",
      "43:\tlearn: 0.1735580\ttotal: 3.58s\tremaining: 4.56s\n",
      "44:\tlearn: 0.1719291\ttotal: 3.65s\tremaining: 4.46s\n",
      "45:\tlearn: 0.1713692\ttotal: 3.68s\tremaining: 4.32s\n",
      "46:\tlearn: 0.1702071\ttotal: 3.71s\tremaining: 4.19s\n",
      "47:\tlearn: 0.1688655\ttotal: 3.75s\tremaining: 4.06s\n",
      "48:\tlearn: 0.1661200\ttotal: 3.79s\tremaining: 3.94s\n",
      "49:\tlearn: 0.1641301\ttotal: 3.83s\tremaining: 3.83s\n",
      "50:\tlearn: 0.1618647\ttotal: 3.87s\tremaining: 3.72s\n",
      "51:\tlearn: 0.1603576\ttotal: 3.9s\tremaining: 3.6s\n",
      "52:\tlearn: 0.1587528\ttotal: 3.94s\tremaining: 3.49s\n",
      "53:\tlearn: 0.1579955\ttotal: 3.97s\tremaining: 3.38s\n",
      "54:\tlearn: 0.1567296\ttotal: 4.02s\tremaining: 3.29s\n",
      "55:\tlearn: 0.1553155\ttotal: 4.06s\tremaining: 3.19s\n",
      "56:\tlearn: 0.1541222\ttotal: 4.11s\tremaining: 3.1s\n",
      "57:\tlearn: 0.1524207\ttotal: 4.15s\tremaining: 3.01s\n",
      "58:\tlearn: 0.1516588\ttotal: 4.2s\tremaining: 2.92s\n",
      "59:\tlearn: 0.1507596\ttotal: 4.25s\tremaining: 2.83s\n",
      "60:\tlearn: 0.1500810\ttotal: 4.29s\tremaining: 2.74s\n",
      "61:\tlearn: 0.1493361\ttotal: 4.33s\tremaining: 2.66s\n",
      "62:\tlearn: 0.1477919\ttotal: 4.38s\tremaining: 2.57s\n",
      "63:\tlearn: 0.1464200\ttotal: 4.42s\tremaining: 2.48s\n",
      "64:\tlearn: 0.1458604\ttotal: 4.46s\tremaining: 2.4s\n",
      "65:\tlearn: 0.1446325\ttotal: 4.49s\tremaining: 2.31s\n",
      "66:\tlearn: 0.1443028\ttotal: 4.53s\tremaining: 2.23s\n",
      "67:\tlearn: 0.1428403\ttotal: 4.57s\tremaining: 2.15s\n",
      "68:\tlearn: 0.1422286\ttotal: 4.61s\tremaining: 2.07s\n",
      "69:\tlearn: 0.1411226\ttotal: 4.65s\tremaining: 1.99s\n",
      "70:\tlearn: 0.1405450\ttotal: 4.68s\tremaining: 1.91s\n",
      "71:\tlearn: 0.1401713\ttotal: 4.72s\tremaining: 1.83s\n",
      "72:\tlearn: 0.1392740\ttotal: 4.75s\tremaining: 1.76s\n",
      "73:\tlearn: 0.1388975\ttotal: 4.79s\tremaining: 1.68s\n",
      "74:\tlearn: 0.1383112\ttotal: 4.83s\tremaining: 1.61s\n",
      "75:\tlearn: 0.1378963\ttotal: 4.86s\tremaining: 1.53s\n",
      "76:\tlearn: 0.1372126\ttotal: 4.89s\tremaining: 1.46s\n",
      "77:\tlearn: 0.1359614\ttotal: 4.93s\tremaining: 1.39s\n",
      "78:\tlearn: 0.1352337\ttotal: 4.96s\tremaining: 1.32s\n",
      "79:\tlearn: 0.1336915\ttotal: 5s\tremaining: 1.25s\n",
      "80:\tlearn: 0.1331432\ttotal: 5.04s\tremaining: 1.18s\n",
      "81:\tlearn: 0.1326263\ttotal: 5.08s\tremaining: 1.11s\n",
      "82:\tlearn: 0.1320527\ttotal: 5.11s\tremaining: 1.05s\n",
      "83:\tlearn: 0.1313294\ttotal: 5.15s\tremaining: 981ms\n",
      "84:\tlearn: 0.1303918\ttotal: 5.19s\tremaining: 916ms\n",
      "85:\tlearn: 0.1300757\ttotal: 5.22s\tremaining: 850ms\n",
      "86:\tlearn: 0.1296247\ttotal: 5.25s\tremaining: 785ms\n",
      "87:\tlearn: 0.1289154\ttotal: 5.3s\tremaining: 722ms\n",
      "88:\tlearn: 0.1282975\ttotal: 5.33s\tremaining: 659ms\n",
      "89:\tlearn: 0.1279106\ttotal: 5.37s\tremaining: 597ms\n",
      "90:\tlearn: 0.1274988\ttotal: 5.4s\tremaining: 534ms\n",
      "91:\tlearn: 0.1272784\ttotal: 5.44s\tremaining: 473ms\n",
      "92:\tlearn: 0.1268224\ttotal: 5.48s\tremaining: 412ms\n",
      "93:\tlearn: 0.1264886\ttotal: 5.53s\tremaining: 353ms\n",
      "94:\tlearn: 0.1258385\ttotal: 5.57s\tremaining: 293ms\n",
      "95:\tlearn: 0.1256629\ttotal: 5.61s\tremaining: 234ms\n",
      "96:\tlearn: 0.1252147\ttotal: 5.67s\tremaining: 175ms\n",
      "97:\tlearn: 0.1249653\ttotal: 5.79s\tremaining: 118ms\n",
      "98:\tlearn: 0.1245979\ttotal: 5.85s\tremaining: 59.1ms\n",
      "99:\tlearn: 0.1243731\ttotal: 5.95s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Model definition\r\n",
    "catboost_model = CatBoostClassifier(iterations= 100, custom_loss= ['Accuracy'], loss_function= 'Logloss')\r\n",
    "\r\n",
    "# Fit CatBoost model\r\n",
    "catboost_model.fit(train_pool, plot= False)\r\n",
    "\r\n",
    "# CatBoost accuracy\r\n",
    "catboost_acc = round(catboost_model.score(X_train_ns, y_train_ns)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6735507\ttest: 0.6735745\tbest: 0.6735745 (0)\n",
      "1:\tlearn: 0.6529239\ttest: 0.6529738\tbest: 0.6529738 (1)\n",
      "2:\tlearn: 0.6376420\ttest: 0.6377065\tbest: 0.6377065 (2)\n",
      "3:\tlearn: 0.6251267\ttest: 0.6251969\tbest: 0.6251969 (3)\ttotal: 5.62s\tremaining: 2m 14s\n",
      "4:\tlearn: 0.6113096\ttest: 0.6114020\tbest: 0.6114020 (4)\n",
      "5:\tlearn: 0.5995553\ttest: 0.5996653\tbest: 0.5996653 (5)\n",
      "6:\tlearn: 0.5855851\ttest: 0.5857072\tbest: 0.5857072 (6)\ttotal: 8.99s\tremaining: 1m 59s\n",
      "7:\tlearn: 0.5736767\ttest: 0.5738188\tbest: 0.5738188 (7)\n",
      "8:\tlearn: 0.5615577\ttest: 0.5617286\tbest: 0.5617286 (8)\n",
      "9:\tlearn: 0.5508472\ttest: 0.5510363\tbest: 0.5510363 (9)\n",
      "10:\tlearn: 0.5399741\ttest: 0.5401680\tbest: 0.5401680 (10)\ttotal: 13.2s\tremaining: 1m 46s\n",
      "11:\tlearn: 0.5321353\ttest: 0.5323736\tbest: 0.5323736 (11)\n",
      "12:\tlearn: 0.5214601\ttest: 0.5217416\tbest: 0.5217416 (12)\n",
      "13:\tlearn: 0.5135052\ttest: 0.5138169\tbest: 0.5138169 (13)\n",
      "14:\tlearn: 0.5066545\ttest: 0.5069547\tbest: 0.5069547 (14)\ttotal: 17.5s\tremaining: 1m 39s\n",
      "15:\tlearn: 0.5006904\ttest: 0.5009624\tbest: 0.5009624 (15)\n",
      "16:\tlearn: 0.4940889\ttest: 0.4943686\tbest: 0.4943686 (16)\n",
      "17:\tlearn: 0.4880777\ttest: 0.4883677\tbest: 0.4883677 (17)\n",
      "18:\tlearn: 0.4816475\ttest: 0.4819471\tbest: 0.4819471 (18)\ttotal: 22.3s\tremaining: 1m 34s\n",
      "19:\tlearn: 0.4765596\ttest: 0.4768047\tbest: 0.4768047 (19)\n",
      "20:\tlearn: 0.4711125\ttest: 0.4713701\tbest: 0.4713701 (20)\n",
      "21:\tlearn: 0.4662165\ttest: 0.4665129\tbest: 0.4665129 (21)\n",
      "22:\tlearn: 0.4614749\ttest: 0.4617826\tbest: 0.4617826 (22)\n",
      "23:\tlearn: 0.4568059\ttest: 0.4571309\tbest: 0.4571309 (23)\ttotal: 27.1s\tremaining: 1m 25s\n",
      "24:\tlearn: 0.4526400\ttest: 0.4530047\tbest: 0.4530047 (24)\n",
      "25:\tlearn: 0.4490633\ttest: 0.4493945\tbest: 0.4493945 (25)\n",
      "26:\tlearn: 0.4459037\ttest: 0.4462498\tbest: 0.4462498 (26)\n",
      "27:\tlearn: 0.4430563\ttest: 0.4434291\tbest: 0.4434291 (27)\ttotal: 30.9s\tremaining: 1m 19s\n",
      "28:\tlearn: 0.4394134\ttest: 0.4397691\tbest: 0.4397691 (28)\n",
      "29:\tlearn: 0.4370347\ttest: 0.4373718\tbest: 0.4373718 (29)\n",
      "30:\tlearn: 0.4341383\ttest: 0.4344877\tbest: 0.4344877 (30)\n",
      "31:\tlearn: 0.4309034\ttest: 0.4312659\tbest: 0.4312659 (31)\n",
      "32:\tlearn: 0.4278700\ttest: 0.4282231\tbest: 0.4282231 (32)\ttotal: 35.4s\tremaining: 1m 11s\n",
      "33:\tlearn: 0.4255544\ttest: 0.4259277\tbest: 0.4259277 (33)\n",
      "34:\tlearn: 0.4222398\ttest: 0.4225911\tbest: 0.4225911 (34)\n",
      "35:\tlearn: 0.4194355\ttest: 0.4197958\tbest: 0.4197958 (35)\n",
      "36:\tlearn: 0.4169736\ttest: 0.4173285\tbest: 0.4173285 (36)\n",
      "37:\tlearn: 0.4135152\ttest: 0.4139138\tbest: 0.4139138 (37)\ttotal: 40.2s\tremaining: 1m 5s\n",
      "38:\tlearn: 0.4107093\ttest: 0.4111628\tbest: 0.4111628 (38)\n",
      "39:\tlearn: 0.4079826\ttest: 0.4084830\tbest: 0.4084830 (39)\n",
      "40:\tlearn: 0.4054043\ttest: 0.4059161\tbest: 0.4059161 (40)\n",
      "41:\tlearn: 0.4030611\ttest: 0.4035276\tbest: 0.4035276 (41)\n",
      "42:\tlearn: 0.4001519\ttest: 0.4006028\tbest: 0.4006028 (42)\n",
      "43:\tlearn: 0.3973310\ttest: 0.3977885\tbest: 0.3977885 (43)\ttotal: 45.4s\tremaining: 57.7s\n",
      "44:\tlearn: 0.3952534\ttest: 0.3956838\tbest: 0.3956838 (44)\n",
      "45:\tlearn: 0.3926445\ttest: 0.3930782\tbest: 0.3930782 (45)\n",
      "46:\tlearn: 0.3902199\ttest: 0.3906375\tbest: 0.3906375 (46)\n",
      "47:\tlearn: 0.3888755\ttest: 0.3893069\tbest: 0.3893069 (47)\n",
      "48:\tlearn: 0.3865553\ttest: 0.3869988\tbest: 0.3869988 (48)\n",
      "49:\tlearn: 0.3833542\ttest: 0.3838837\tbest: 0.3838837 (49)\ttotal: 50.5s\tremaining: 50.5s\n",
      "50:\tlearn: 0.3820436\ttest: 0.3825804\tbest: 0.3825804 (50)\n",
      "51:\tlearn: 0.3798754\ttest: 0.3804354\tbest: 0.3804354 (51)\n",
      "52:\tlearn: 0.3771860\ttest: 0.3776587\tbest: 0.3776587 (52)\n",
      "53:\tlearn: 0.3750463\ttest: 0.3755017\tbest: 0.3755017 (53)\n",
      "54:\tlearn: 0.3734921\ttest: 0.3739389\tbest: 0.3739389 (54)\ttotal: 55.1s\tremaining: 45.1s\n",
      "55:\tlearn: 0.3714661\ttest: 0.3719210\tbest: 0.3719210 (55)\n",
      "56:\tlearn: 0.3698323\ttest: 0.3703233\tbest: 0.3703233 (56)\n",
      "57:\tlearn: 0.3673413\ttest: 0.3678050\tbest: 0.3678050 (57)\n",
      "58:\tlearn: 0.3655334\ttest: 0.3660373\tbest: 0.3660373 (58)\ttotal: 58.7s\tremaining: 40.8s\n",
      "59:\tlearn: 0.3628973\ttest: 0.3634065\tbest: 0.3634065 (59)\n",
      "60:\tlearn: 0.3604209\ttest: 0.3609058\tbest: 0.3609058 (60)\n",
      "61:\tlearn: 0.3584273\ttest: 0.3589199\tbest: 0.3589199 (61)\n",
      "62:\tlearn: 0.3560789\ttest: 0.3565830\tbest: 0.3565830 (62)\ttotal: 1m 2s\tremaining: 36.6s\n",
      "63:\tlearn: 0.3543492\ttest: 0.3548607\tbest: 0.3548607 (63)\n",
      "64:\tlearn: 0.3517485\ttest: 0.3522879\tbest: 0.3522879 (64)\n",
      "65:\tlearn: 0.3494605\ttest: 0.3499951\tbest: 0.3499951 (65)\n",
      "66:\tlearn: 0.3480316\ttest: 0.3485767\tbest: 0.3485767 (66)\n",
      "67:\tlearn: 0.3455732\ttest: 0.3461187\tbest: 0.3461187 (67)\n",
      "68:\tlearn: 0.3437123\ttest: 0.3442863\tbest: 0.3442863 (68)\ttotal: 1m 7s\tremaining: 30.3s\n",
      "69:\tlearn: 0.3419640\ttest: 0.3425117\tbest: 0.3425117 (69)\n",
      "70:\tlearn: 0.3400002\ttest: 0.3405550\tbest: 0.3405550 (70)\n",
      "71:\tlearn: 0.3380498\ttest: 0.3386113\tbest: 0.3386113 (71)\n",
      "72:\tlearn: 0.3358969\ttest: 0.3364632\tbest: 0.3364632 (72)\ttotal: 1m 11s\tremaining: 26.3s\n",
      "73:\tlearn: 0.3337490\ttest: 0.3342997\tbest: 0.3342997 (73)\n",
      "74:\tlearn: 0.3317712\ttest: 0.3323195\tbest: 0.3323195 (74)\n",
      "75:\tlearn: 0.3301646\ttest: 0.3307635\tbest: 0.3307635 (75)\n",
      "76:\tlearn: 0.3280668\ttest: 0.3286801\tbest: 0.3286801 (76)\n",
      "77:\tlearn: 0.3256361\ttest: 0.3261903\tbest: 0.3261903 (77)\n",
      "78:\tlearn: 0.3242427\ttest: 0.3247855\tbest: 0.3247855 (78)\ttotal: 1m 16s\tremaining: 20.3s\n",
      "79:\tlearn: 0.3227104\ttest: 0.3232780\tbest: 0.3232780 (79)\n",
      "80:\tlearn: 0.3203873\ttest: 0.3209697\tbest: 0.3209697 (80)\n",
      "81:\tlearn: 0.3193305\ttest: 0.3199273\tbest: 0.3199273 (81)\n",
      "82:\tlearn: 0.3172749\ttest: 0.3178486\tbest: 0.3178486 (82)\n",
      "83:\tlearn: 0.3158681\ttest: 0.3164727\tbest: 0.3164727 (83)\ttotal: 1m 21s\tremaining: 15.5s\n",
      "84:\tlearn: 0.3142736\ttest: 0.3148914\tbest: 0.3148914 (84)\n",
      "85:\tlearn: 0.3131785\ttest: 0.3138062\tbest: 0.3138062 (85)\n",
      "86:\tlearn: 0.3111803\ttest: 0.3117790\tbest: 0.3117790 (86)\n",
      "87:\tlearn: 0.3098307\ttest: 0.3104073\tbest: 0.3104073 (87)\n",
      "88:\tlearn: 0.3078488\ttest: 0.3084256\tbest: 0.3084256 (88)\n",
      "89:\tlearn: 0.3062418\ttest: 0.3068801\tbest: 0.3068801 (89)\ttotal: 1m 26s\tremaining: 9.65s\n",
      "90:\tlearn: 0.3041905\ttest: 0.3048140\tbest: 0.3048140 (90)\n",
      "91:\tlearn: 0.3030960\ttest: 0.3036997\tbest: 0.3036997 (91)\n",
      "92:\tlearn: 0.3017745\ttest: 0.3023844\tbest: 0.3023844 (92)\n",
      "93:\tlearn: 0.3001346\ttest: 0.3007007\tbest: 0.3007007 (93)\ttotal: 1m 30s\tremaining: 5.79s\n",
      "94:\tlearn: 0.2992395\ttest: 0.2998119\tbest: 0.2998119 (94)\n",
      "95:\tlearn: 0.2981435\ttest: 0.2987369\tbest: 0.2987369 (95)\n",
      "96:\tlearn: 0.2966131\ttest: 0.2971701\tbest: 0.2971701 (96)\ttotal: 1m 33s\tremaining: 2.9s\n",
      "97:\tlearn: 0.2950629\ttest: 0.2956084\tbest: 0.2956084 (97)\n",
      "98:\tlearn: 0.2932538\ttest: 0.2938000\tbest: 0.2938000 (98)\n",
      "99:\tlearn: 0.2920652\ttest: 0.2926388\tbest: 0.2926388 (99)\ttotal: 1m 36s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Cross Validation\r\n",
    "start_time = time.time()\r\n",
    "\r\n",
    "# Set the parameters for cross validation as same as the initial model\r\n",
    "cv_param = catboost_model.get_params()\r\n",
    "\r\n",
    "# Run 10-Folds CV\r\n",
    "cv_data = cv(train_pool, cv_param, fold_count= 10, plot= False)\r\n",
    "\r\n",
    "# How long does it take?\r\n",
    "catboost_time = (time.time()- start_time)\r\n",
    "\r\n",
    "# CatBoost results get saved into a dataframe,the maximum accuracy score is\r\n",
    "catboost_acc_cv = round(np.max(cv_data['test-Accuracy-mean'])*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  95.91\n",
      "Accuracy of 10-Fold CV is:  86.64\n",
      "Running time is:  0:01:37.487928\n"
     ]
    }
   ],
   "source": [
    "#  CatBoost Algorithm\r\n",
    "print('Accuracy of the model is: ', catboost_acc)\r\n",
    "print('Accuracy of 10-Fold CV is: ', catboost_acc_cv)\r\n",
    "print('Running time is: ', datetime.timedelta(seconds= catboost_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results\r\n",
    "\r\n",
    "Now let's see which model has the best cross-validation accuracy.\r\n",
    "\r\n",
    "- <b>NOTE:</b> We care more about the accuracy of cross validation, as the metrics we get from the model can randomly score higher than usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Cross-Validation Accuracy Scores-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>95.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>94.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbours</td>\n",
       "      <td>90.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost Trees</td>\n",
       "      <td>87.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost Algorithm</td>\n",
       "      <td>86.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Support Vector Machines (SVC)</td>\n",
       "      <td>72.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>72.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>72.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>67.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  Score\n",
       "7                         Random Forest  95.42\n",
       "5              Decision Tree Classifier  94.06\n",
       "1                  K-Nearest Neighbours  90.36\n",
       "6                  Gradient Boost Trees  87.62\n",
       "8                    CatBoost Algorithm  86.64\n",
       "3  Linear Support Vector Machines (SVC)  72.50\n",
       "4           Stochastic Gradient Descent  72.22\n",
       "0                   Logistic Regression  72.08\n",
       "2                  Gaussian Naive Bayes  67.73"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_models = pd.DataFrame({'Model':[' Logistic Regression', 'K-Nearest Neighbours', 'Gaussian Naive Bayes', \r\n",
    "                                'Linear Support Vector Machines (SVC)', 'Stochastic Gradient Descent', \r\n",
    "                                'Decision Tree Classifier', 'Gradient Boost Trees', 'Random Forest', 'CatBoost Algorithm'],\r\n",
    "                      'Score':[log_acc_cv, knn_acc_cv, gnb_acc_cv, svc_acc_cv, SGD_acc_cv, dt_acc_cv, gbt_acc_cv, rf_acc_cv, \r\n",
    "                               catboost_acc_cv]})\r\n",
    "\r\n",
    "print('-----Cross-Validation Accuracy Scores-----')\r\n",
    "cv_models.nlargest(9,'Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\r\n",
    "\r\n",
    "Precision and Recall are metrics that you use when you have an imbalanced classification problem.\r\n",
    "\r\n",
    "- Recall - a metric which measures a models ability to find all relevant cases in a dataset.\r\n",
    "- Precision - a metric which measures a models ability to correctly identify only relevant cases.\r\n",
    "\r\n",
    "Combining  Precision and Recall gives us the **F1 score.**\r\n",
    "\r\n",
    "They fall between 0 and 1, with 1 being better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Cross-Validation Accuracy Scores-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.953890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.940164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbours</td>\n",
       "      <td>0.907766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost Trees</td>\n",
       "      <td>0.881897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.732752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Support Vector Machines (SVC)</td>\n",
       "      <td>0.725723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.719757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.623617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  F1-Score\n",
       "7                         Random Forest  0.953890\n",
       "5              Decision Tree Classifier  0.940164\n",
       "1                  K-Nearest Neighbours  0.907766\n",
       "6                  Gradient Boost Trees  0.881897\n",
       "4           Stochastic Gradient Descent  0.732752\n",
       "3  Linear Support Vector Machines (SVC)  0.725723\n",
       "0                   Logistic Regression  0.719757\n",
       "2                  Gaussian Naive Bayes  0.623617"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_cv_models = pd.DataFrame({'Model':[' Logistic Regression', 'K-Nearest Neighbours', 'Gaussian Naive Bayes', \r\n",
    "                                'Linear Support Vector Machines (SVC)', 'Stochastic Gradient Descent', \r\n",
    "                                'Decision Tree Classifier', 'Gradient Boost Trees', 'Random Forest'],\r\n",
    "                      'F1-Score':[log_f1_cv, knn_f1_cv, gnb_f1_cv, svc_f1_cv, SGD_f1_cv, dt_f1_cv, gbt_f1_cv, rf_f1_cv]})\r\n",
    "\r\n",
    "print('-----Cross-Validation Accuracy Scores-----')\r\n",
    "f1_cv_models.nlargest(8,'F1-Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9324237850221612\n",
      "Recall: 0.9235191686844231\n",
      "F1: 0.9265853789951105\n",
      "AUC: 0.9769019482035128\n"
     ]
    }
   ],
   "source": [
    "metrics = ['Precision', 'Recall', 'F1', 'AUC']\r\n",
    "\r\n",
    "eval_metrics = catboost_model.eval_metrics(train_pool, metrics= metrics, plot= False)\r\n",
    "\r\n",
    "for metric in metrics:\r\n",
    "    print(str(metric)+ ': {}' .format(np.mean(eval_metrics[metric])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Recall = TP/(TP + FN)**\r\n",
    "- Here the Recall is pretty high. This means that there is a lesser amount of False Negatives (predicting 'Did not launch' when it was actually 'Launched').\r\n",
    "\r\n",
    "> **Pression = TP/(TP + FP)**\r\n",
    "- Precision is high. Thus, we can say say that there is less False Positives (predicting 'Launched' when it actually 'Did not launch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\r\n",
    "\r\n",
    "Let's use the model with the highest cross-validation accuracy score to make a prediction on the test dataset.\r\n",
    "\r\n",
    "We want to make predictions on the same columnns our model is trained on.\r\n",
    "\r\n",
    "So we have to select the subset of right columns of the test dateframe, encode them and make a prediciton with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['department', 'gender', 'recruitment_channel', 'no_of_trainings', 'age',\n",
       "       'previous_year_rating', 'length_of_service', 'KPIs_met >80%',\n",
       "       'awards_won?', 'avg_training_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of columns to be used for predictions.\r\n",
    "wanted_columns = X_train.columns\r\n",
    "wanted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using RandomForest model on wanted columns.\r\n",
    "from sklearn.model_selection import cross_val_predict\r\n",
    "predictions = algorithm.predict(X_test[wanted_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  0.9763729246487867\n",
      "Precision:  0.8540268456375839\n",
      "Recall:  0.8559417040358744\n",
      "F1:  0.8549832026875701\n"
     ]
    }
   ],
   "source": [
    "#  RandomForest Algorithm\r\n",
    "print('Accuracy of the model is: ', accuracy_score(y_test, predictions))\r\n",
    "print('Precision: ', precision_score(y_test, predictions))\r\n",
    "print('Recall: ', recall_score(y_test, predictions))\r\n",
    "print('F1: ', f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction on the Test dataset\r\n",
    "\r\n",
    "Let's use the model with the highest cross-validation accuracy score to make a prediction on the test dataset.\r\n",
    "\r\n",
    "We want to make predictions on the same columnns our model is trained on.\r\n",
    "\r\n",
    "So we have to select the subset of right columns of the test dateframe, encode them and make a prediciton with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.206058</td>\n",
       "      <td>0.644516</td>\n",
       "      <td>1.154134</td>\n",
       "      <td>-0.423094</td>\n",
       "      <td>-1.283525</td>\n",
       "      <td>-0.266732</td>\n",
       "      <td>-1.143200</td>\n",
       "      <td>1.336715</td>\n",
       "      <td>-0.152665</td>\n",
       "      <td>1.024263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.180154</td>\n",
       "      <td>-1.551551</td>\n",
       "      <td>-0.883722</td>\n",
       "      <td>-0.423094</td>\n",
       "      <td>-0.282097</td>\n",
       "      <td>-0.266732</td>\n",
       "      <td>-0.192590</td>\n",
       "      <td>-0.748103</td>\n",
       "      <td>-0.152665</td>\n",
       "      <td>-0.914377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.808356</td>\n",
       "      <td>0.644516</td>\n",
       "      <td>-0.883722</td>\n",
       "      <td>-0.423094</td>\n",
       "      <td>-0.282097</td>\n",
       "      <td>-1.907786</td>\n",
       "      <td>-0.430243</td>\n",
       "      <td>-0.748103</td>\n",
       "      <td>-0.152665</td>\n",
       "      <td>-1.212629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012952</td>\n",
       "      <td>-1.551551</td>\n",
       "      <td>-0.883722</td>\n",
       "      <td>2.905264</td>\n",
       "      <td>-0.282097</td>\n",
       "      <td>-1.087259</td>\n",
       "      <td>0.758019</td>\n",
       "      <td>-0.748103</td>\n",
       "      <td>-0.152665</td>\n",
       "      <td>0.129506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.577856</td>\n",
       "      <td>0.644516</td>\n",
       "      <td>1.154134</td>\n",
       "      <td>-0.423094</td>\n",
       "      <td>-0.282097</td>\n",
       "      <td>0.553794</td>\n",
       "      <td>0.282714</td>\n",
       "      <td>-0.748103</td>\n",
       "      <td>-0.152665</td>\n",
       "      <td>-0.168746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department    gender  recruitment_channel  no_of_trainings       age  \\\n",
       "0    1.206058  0.644516             1.154134        -0.423094 -1.283525   \n",
       "1   -1.180154 -1.551551            -0.883722        -0.423094 -0.282097   \n",
       "2    0.808356  0.644516            -0.883722        -0.423094 -0.282097   \n",
       "3    0.012952 -1.551551            -0.883722         2.905264 -0.282097   \n",
       "4   -1.577856  0.644516             1.154134        -0.423094 -0.282097   \n",
       "\n",
       "   previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "0             -0.266732          -1.143200       1.336715    -0.152665   \n",
       "1             -0.266732          -0.192590      -0.748103    -0.152665   \n",
       "2             -1.907786          -0.430243      -0.748103    -0.152665   \n",
       "3             -1.087259           0.758019      -0.748103    -0.152665   \n",
       "4              0.553794           0.282714      -0.748103    -0.152665   \n",
       "\n",
       "   avg_training_score  \n",
       "0            1.024263  \n",
       "1           -0.914377  \n",
       "2           -1.212629  \n",
       "3            0.129506  \n",
       "4           -0.168746  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop(columns= 'education', inplace= True)\r\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using RandomForest model on wanted columns.\r\n",
    "predictions = algorithm.predict(test[wanted_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our predictions array is comprised of 0's and 1's.\r\n",
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id  is_promoted\n",
       "0         8724            1\n",
       "1        74430            0\n",
       "2        72255            0\n",
       "3        38562            0\n",
       "4        64486            0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',100)\r\n",
    "df = pd.read_csv('test.csv')\r\n",
    "\r\n",
    "# Create a dataframe and append the relevant colimns.\r\n",
    "submission = pd.DataFrame()\r\n",
    "submission['employee_id'] = df['employee_id']\r\n",
    "submission['is_promoted'] = predictions\r\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13338\n",
       "0    10152\n",
       "Name: is_promoted, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['is_promoted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission and the test dataframes are of the same length\n"
     ]
    }
   ],
   "source": [
    "# Are our test and submission the same length?\r\n",
    "if len(submission) == len(test):\r\n",
    "    print('The submission and the test dataframes are of the same length')\r\n",
    "else:\r\n",
    "    print('Dataframes mismatched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission csv is ready\n"
     ]
    }
   ],
   "source": [
    "# convert submission dataframe to csv.\r\n",
    "submission.to_csv('HR_Analytics.csv', index= False)\r\n",
    "print('Submission csv is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6c8cccf23fc189a51b8b2ae4ca3b98de763e12cce4f9033fe8d82721c91cecc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}